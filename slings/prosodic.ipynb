{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prosodic parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "STONES = ['parse_by_line', 'parse_by_window']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_path1='/Volumes/Present/DH/corpora/chadwyck_poetry/xml/african-american/beadlesa/Z200265018.xml'\n",
    "eg_path2='/Volumes/Present/DH/corpora/chadwyck_poetry/xml/english/miscell2/Z200439011.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prosodic as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_plain(path, OK=['l','lb'], BAD=['note','edit'], body_tag='poem', line_lim=None, modernize_spelling=True):\n",
    "    from llp.corpus.chadwyck_poetry import xml2txt\n",
    "    return xml2txt(path, OK=OK,BAD=BAD,body_tag=body_tag,line_lim=line_lim,modernize_spelling=modernize_spelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_plain(eg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path_to_txt_or_xml_file):\n",
    "    try:\n",
    "        if path_to_txt_or_xml_file.endswith('.xml'):\n",
    "            txt=text_plain(path_to_txt_or_xml_file)\n",
    "        else:\n",
    "            with open(path_to_txt_or_xml_file) as f:\n",
    "                txt=f.read()\n",
    "        return txt\n",
    "    except IOError:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts(string, sub):\n",
    "    count = start = 0\n",
    "    while True:\n",
    "        start = string.find(sub, start) + 1\n",
    "        if start > 0:\n",
    "            count+=1\n",
    "        else:\n",
    "            return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw string parsing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_line(line,meter,require_parse_data=True):\n",
    "    \"\"\"\n",
    "    Get data from the prosodic line object, with its meter.\n",
    "    \"\"\"\n",
    "    \n",
    "    # get phonological info\n",
    "    weight_str=line.str_weight()\n",
    "    sonority_str=line.str_sonority()\n",
    "    stress_str=line.str_stress()\n",
    "\n",
    "    # store metrical constraint stats\n",
    "    bp=line.bestParse(meter)\n",
    "    \n",
    "    # require \n",
    "    if require_parse_data:\n",
    "        if not bp:\n",
    "            return {}\n",
    "        \n",
    "    ap=line.allParses(meter)\n",
    "    output_dict={}\n",
    "    output_dict['prosodic_line']=line.txt #.encode('utf-8',errors='ignore')\n",
    "    output_dict['parse']=bp.posString(viols=True) if bp else ''\n",
    "    #output_dict['parse']=output_dict['parse'] #.encode('utf-8',errors='ignore')\n",
    "    meter_str=output_dict['meter']=bp.str_meter() if bp else ''\n",
    "    output_dict['num_parses']=len(ap)\n",
    "    output_dict['num_viols'] = bp.totalCount if bp else ''\n",
    "    output_dict['score_viols'] = bp.score() if bp else ''\n",
    "    output_dict['num_sylls']=bp.num_sylls if bp else ''\n",
    "    output_dict['num_words']=len(line.words())\n",
    "    for c in meter.constraints:\n",
    "        sumviol = sum([parse.constraintCounts[c] if c in parse.constraintCounts else 0 for parse in ap])\n",
    "        output_dict[c.name_weight+'_bestparse']=bp.constraintCounts[c] if bp and c in bp.constraintCounts else 0\n",
    "        output_dict[c.name_weight+'_allparse_sum']=sumviol if sumviol else 0\n",
    "    \n",
    "    ## store phonological constraint stats\n",
    "    output_dict['prosodic_stress']=stress_str\n",
    "    output_dict['prosodic_weight']=weight_str\n",
    "    output_dict['prosodic_sonority']=sonority_str\n",
    "    output_dict['num_monosylls']=len([w for w in line.words() if w.numSyll==1])\n",
    "    output_dict['[*clash_across]']=counts(stress_str,'P#P') + counts(stress_str,'P#S') + counts(stress_str,'S#P') + counts(stress_str,'S#S')\n",
    "    output_dict['[*clash_within]']=counts(stress_str,'PP') + counts(stress_str,'PS') + counts(stress_str,'SP') + counts(stress_str,'SS')\n",
    "    output_dict['[*clash_across_primary]']=counts(stress_str,'P#P')\n",
    "    output_dict['[*clash_within_primary]']=counts(stress_str,'PP')\n",
    "    output_dict['[*lapse_across]']=counts(stress_str,'U#U')\n",
    "    output_dict['[*lapse_within]']=counts(stress_str,'UU')\n",
    "    output_dict['[*WSP]']=0\n",
    "    output_dict['[*PEAKPROM]']=0\n",
    "    output_dict['[*High_Stress]']=0\n",
    "    output_dict['[*Low_Unstress]']=0\n",
    "    output_dict['[*High_Strong]']=0\n",
    "    output_dict['[*Low_Weak]']=0\n",
    "    for s,w,hml,mtr in zip(stress_str,weight_str,sonority_str,meter_str):\n",
    "        if s=='U' and w=='H':\n",
    "            output_dict['[*WSP]']+=1\n",
    "        if (s=='P' or s=='S') and w=='L':\n",
    "            output_dict['[*PEAKPROM]']+=1\n",
    "        \n",
    "        if hml=='H' and s in {'P','S'}:\n",
    "            output_dict['[*High_Stress]']+=1\n",
    "        if hml=='L' and s==\"U\":\n",
    "            output_dict['[*Low_Unstress]']+=1\n",
    "        \n",
    "        if hml=='H' and mtr == 's':\n",
    "            output_dict['[*High_Strong]']+=1\n",
    "        if hml=='L' and mtr == 'w':\n",
    "            output_dict['[*Low_Weak]']+=1\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_string(text_str, meter='default_english', num_processes=1):\n",
    "    \"\"\"\n",
    "    Parse the string, assuming line as unit\n",
    "    \"\"\"\n",
    "    # prosodic parse\n",
    "    text = p.Text(text_str)\n",
    "    meter = text.get_meter(meter)\n",
    "\n",
    "    out_ld=[]\n",
    "    for i,line in enumerate(text.iparse(meter=meter, num_processes=num_processes)):\n",
    "        line_d=get_data_from_line(line,meter)\n",
    "        if not line_d or not 'score_viols' in line_d: continue\n",
    "        line_d['line_id']=i+1\n",
    "        out_ld.append(line_d)\n",
    "    return out_ld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.DataFrame(parse_string(\"\"\"With what attractive charms this goodly frame \n",
    "# Of nature touches the consenting hearts \n",
    "# Of mortal men; and what the pleasing stores \n",
    "# Which beauteous imitation thence derives \n",
    "# To deck the poet's, or the painter's toil; \n",
    "# My verse unfolds.\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By line in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_by_line(path_to_txt_or_xml_file, meter='default_english', num_processes=1):\n",
    "    # get txt\n",
    "    txt=read_file(path_to_txt_or_xml_file)\n",
    "    \n",
    "    # return parse\n",
    "    return parse_string(txt, meter=meter, num_processes=num_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.DataFrame(parse_by_line(eg_path)).sort_values('score_viols').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df_window1=pd.DataFrame(parse_by_line(eg_path1))\n",
    "# df_window2=pd.DataFrame(parse_by_line(eg_path2))\n",
    "# print(df_window1.mean()['score_viols'], df_window2.mean()['score_viols'])\n",
    "# df_window2.sort_values('num_viols').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice(l,num_slices=None,slice_length=None,runts=True,random=False):\n",
    "    \"\"\"\n",
    "    Returns a new list of n evenly-sized segments of the original list\n",
    "    \"\"\"\n",
    "    if random:\n",
    "        import random\n",
    "        random.shuffle(l)\n",
    "    if not num_slices and not slice_length: return l\n",
    "    if not slice_length: slice_length=int(len(l)/num_slices)\n",
    "    newlist=[l[i:i+slice_length] for i in range(0, len(l), slice_length)]\n",
    "    if runts: return newlist\n",
    "    return [lx for lx in newlist if len(lx)==slice_length]\n",
    "\n",
    "def ngram(l,n=3):\n",
    "    grams=[]\n",
    "    gram=[]\n",
    "    for x in l:\n",
    "        gram.append(x)\n",
    "        if len(gram)<n: continue\n",
    "        g=tuple(gram)\n",
    "        grams.append(g)\n",
    "        gram.reverse()\n",
    "        gram.pop()\n",
    "        gram.reverse()\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slice(read_file(eg_path).split(), slice_length=5)\n",
    "#len(ngram(read_file(eg_path).split(), n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_by_window(path_to_txt_or_xml_file, meter='default_english', window_size=5,overlapping_windows=False,max_slices=100000,num_processes=1,):\n",
    "    # get txt\n",
    "    txt=read_file(path_to_txt_or_xml_file)\n",
    "    words=txt.split()\n",
    "    \n",
    "    if overlapping_windows:\n",
    "        word_slices = ngram(words,n=window_size)\n",
    "    else:\n",
    "        word_slices = slice(words,slice_length=window_size)\n",
    "        word_slices = word_slices[:max_slices]\n",
    "        \n",
    "    txt = '\\n'.join([' '.join(slicex) for slicex in word_slices])\n",
    "    \n",
    "    return parse_string(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df_window1=pd.DataFrame(parse_by_window(eg_path1))\n",
    "# df_window2=pd.DataFrame(parse_by_window(eg_path2))\n",
    "# print(df_window1.mean()['score_viols'], df_window2.mean()['score_viols'])\n",
    "# df_window2.sort_values('num_viols').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires NLTK\n",
    "def parse_by_phrase(path_to_txt_or_xml_file, meter='default_english', minword=5):\n",
    "    # get txt\n",
    "    txt=read_file(path_to_txt_or_xml_file)\n",
    "    \n",
    "    # phrases\n",
    "    import re\n",
    "    phrases=re.split('[?.,;:\\n]', txt)\n",
    "    \n",
    "    # recombine for minword\n",
    "    if minword:\n",
    "        phrases2=[]\n",
    "        phrase=[]\n",
    "        for px in phrases:\n",
    "            phrase+=px.split()\n",
    "            if len(phrase)>=minword:\n",
    "                phrases2+=[' '.join(phrase)]\n",
    "                phrase=[]\n",
    "        phrases=phrases2\n",
    "    \n",
    "    # make txt\n",
    "    txt = '\\n'.join(phrases)\n",
    "\n",
    "    # return parsed\n",
    "    return parse_string(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> parsing complete in: 1.2151060104370117 seconds\n",
      ">> parsing line # 100 of 127 lines [ 485.8 syllables/second ]\n",
      ">> parsing complete in: 0.4264261722564697 seconds\n",
      "1.4 0.9921259842519685\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[*High_Stress]</th>\n",
       "      <th>[*High_Strong]</th>\n",
       "      <th>[*Low_Unstress]</th>\n",
       "      <th>[*Low_Weak]</th>\n",
       "      <th>[*PEAKPROM]</th>\n",
       "      <th>[*WSP]</th>\n",
       "      <th>[*clash_across]</th>\n",
       "      <th>[*clash_across_primary]</th>\n",
       "      <th>[*clash_within]</th>\n",
       "      <th>[*clash_within_primary]</th>\n",
       "      <th>...</th>\n",
       "      <th>num_parses</th>\n",
       "      <th>num_sylls</th>\n",
       "      <th>num_viols</th>\n",
       "      <th>num_words</th>\n",
       "      <th>parse</th>\n",
       "      <th>prosodic_line</th>\n",
       "      <th>prosodic_sonority</th>\n",
       "      <th>prosodic_stress</th>\n",
       "      <th>prosodic_weight</th>\n",
       "      <th>score_viols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>the|CUR|few|TOLLS|the|KNELL|of|PART|ing|DAY</td>\n",
       "      <td>The curfew tolls the knell of parting day</td>\n",
       "      <td>LLHMLLLLHM</td>\n",
       "      <td>UPUPUPUPUP</td>\n",
       "      <td>LHHHLHLHHH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>BACK|to.its|MAN|sion|CALL|the|FLEET|ing|BREATH</td>\n",
       "      <td>Back to its mansion call the fleeting breath</td>\n",
       "      <td>LHHLLLLHHL</td>\n",
       "      <td>PUUPUPUPUP</td>\n",
       "      <td>HLLHHHLHHH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>HANDS|that.the|ROD|of|EM|pire|MIGHT|have|SWAYED</td>\n",
       "      <td>Hands that the rod of empire might have swayed</td>\n",
       "      <td>LLLLLLMMLM</td>\n",
       "      <td>PUUPUPUPUP</td>\n",
       "      <td>HLLHLHHHHH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>and|FROZE|the|GE|nial|CURRENT|of.the|SOUL</td>\n",
       "      <td>And froze the genial current of the soul</td>\n",
       "      <td>LMLHLLLLM</td>\n",
       "      <td>UPUPUPUUP</td>\n",
       "      <td>LHLHHHLLH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>the|DARK|unfathomed|CAVES|of|OCEAN||BEAR</td>\n",
       "      <td>The dark unfathomed caves of ocean bear</td>\n",
       "      <td>LLMMLMLL</td>\n",
       "      <td>UPUPUPUP</td>\n",
       "      <td>LHHHLHHH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    [*High_Stress]  [*High_Strong]  [*Low_Unstress]  [*Low_Weak]  [*PEAKPROM]  \\\n",
       "0                0               0                3            3            0   \n",
       "40               1               1                2            2            0   \n",
       "45               0               0                4            4            0   \n",
       "50               1               1                5            5            0   \n",
       "52               0               0                3            3            0   \n",
       "\n",
       "    [*WSP]  [*clash_across]  [*clash_across_primary]  [*clash_within]  \\\n",
       "0        2                0                        0                0   \n",
       "40       2                0                        0                0   \n",
       "45       2                0                        0                0   \n",
       "50       1                0                        0                0   \n",
       "52       2                0                        0                0   \n",
       "\n",
       "    [*clash_within_primary]  ...  num_parses  num_sylls  num_viols  num_words  \\\n",
       "0                         0  ...           1         10          0          8   \n",
       "40                        0  ...           1         10          0          8   \n",
       "45                        0  ...           1         10          0          9   \n",
       "50                        0  ...           1          9          0          8   \n",
       "52                        0  ...           1          8          0          7   \n",
       "\n",
       "                                              parse  \\\n",
       "0       the|CUR|few|TOLLS|the|KNELL|of|PART|ing|DAY   \n",
       "40   BACK|to.its|MAN|sion|CALL|the|FLEET|ing|BREATH   \n",
       "45  HANDS|that.the|ROD|of|EM|pire|MIGHT|have|SWAYED   \n",
       "50        and|FROZE|the|GE|nial|CURRENT|of.the|SOUL   \n",
       "52         the|DARK|unfathomed|CAVES|of|OCEAN||BEAR   \n",
       "\n",
       "                                     prosodic_line  prosodic_sonority  \\\n",
       "0        The curfew tolls the knell of parting day         LLHMLLLLHM   \n",
       "40    Back to its mansion call the fleeting breath         LHHLLLLHHL   \n",
       "45  Hands that the rod of empire might have swayed         LLLLLLMMLM   \n",
       "50        And froze the genial current of the soul          LMLHLLLLM   \n",
       "52         The dark unfathomed caves of ocean bear           LLMMLMLL   \n",
       "\n",
       "    prosodic_stress  prosodic_weight  score_viols  \n",
       "0        UPUPUPUPUP       LHHHLHLHHH            0  \n",
       "40       PUUPUPUPUP       HLLHHHLHHH            0  \n",
       "45       PUUPUPUPUP       HLLHLHHHHH            0  \n",
       "50        UPUPUPUUP        LHLHHHLLH            0  \n",
       "52         UPUPUPUP         LHHHLHHH            0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_window1=pd.DataFrame(parse_by_phrase(eg_path1))\n",
    "df_window2=pd.DataFrame(parse_by_phrase(eg_path2))\n",
    "print(df_window1.mean()['score_viols'], df_window2.mean()['score_viols'])\n",
    "df_window2.sort_values('score_viols').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
